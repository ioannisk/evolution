

python train_snli.py cbow petModel-0 --keep_rate 0.9 --seq_length 25 --emb_to_load /home/ioannis/data/glove --datapath /home/ioannis/data

nohup python train_snli.py bilstm petModel-12 --seq_length 50 --keep_rate 0.8 --learning_rate 0.0001 &


python train_snli.py esim petModel-3 --seq_length 50 --keep_rate 0.8 --learning_rate 0.0001

python train_snli.py esim petModel-11 --seq_length 25 --keep_rate 0.8 --learning_rate 0.0001



#
#snli-entailment
#
python tf_model.py -train snli_1.0_train.tab -dev snli_1.0_dev.tab -test snli_1.0_test.tab



I think it works normally
fucking finally
#
# entailment-neural-attention-lstm-tf
#
nohup python main.py --data_dir /home/ioannis/data/snli_1.0 --model_name test --gpu '' --word2vec_path /home/ioannis/scp/GoogleNews-vectors-negative300.bin --train --sequence_length 50 &
nohup python main.py --data_dir /home/ioannis/data/snli_1.0 --model_name test_1  --word2vec_path /home/ioannis/scp/GoogleNews-vectors-negative300.bin --train --sequence_length 50 &

python tf_upgrade.py --infile main.py --outfile main.py
